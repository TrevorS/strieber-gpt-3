{
  "_meta": {
    "description": "Qwen Image text-to-image workflow (API format)",
    "nodes": {
      "1": "CheckpointLoaderSimple - Load Qwen model",
      "2": "EmptyLatentImage - Set image dimensions",
      "3": "CLIPTextEncode - Positive prompt",
      "4": "CLIPTextEncode - Negative prompt",
      "5": "KSampler - Main sampling",
      "6": "VAEDecode - Decode latents",
      "7": "SaveImage - Save output"
    },
    "parameters": {
      "node_2": {
        "width": "Image width",
        "height": "Image height",
        "batch_size": "Number of images"
      },
      "node_3": {
        "text": "Positive prompt"
      },
      "node_4": {
        "text": "Negative prompt"
      },
      "node_5": {
        "seed": "Random seed",
        "steps": "Sampling steps",
        "cfg": "Guidance scale",
        "sampler_name": "Sampler algorithm",
        "scheduler": "Scheduler type"
      }
    }
  },
  "1": {
    "inputs": {
      "ckpt_name": "qwen-vl-base.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "2": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "3": {
    "inputs": {
      "text": "beautiful landscape, high quality",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "4": {
    "inputs": {
      "text": "blurry, low quality, distorted",
      "clip": ["1", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "5": {
    "inputs": {
      "seed": 42,
      "steps": 20,
      "cfg": 5.0,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1.0,
      "model": ["1", 0],
      "positive": ["3", 0],
      "negative": ["4", 0],
      "latent_image": ["2", 0]
    },
    "class_type": "KSampler"
  },
  "6": {
    "inputs": {
      "samples": ["5", 0],
      "vae": ["1", 2]
    },
    "class_type": "VAEDecode"
  },
  "7": {
    "inputs": {
      "filename_prefix": "qwen_txt2img",
      "images": ["6", 0]
    },
    "class_type": "SaveImage"
  }
}
