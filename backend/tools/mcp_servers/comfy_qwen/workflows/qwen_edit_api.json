{
  "_comment": "Qwen Image Edit (img2img/inpaint) workflow with Lightning LoRA support.",
  "_instructions": "Export your ComfyUI workflow in API format and replace this file. Update NODE_MAPPINGS in server.py to match your actual node IDs.",
  "_node_mapping": {
    "checkpoint_loader": "Node ID 1 - Loads the Qwen model checkpoint",
    "lora_loader": "Node ID 10 - LoraLoaderModelOnly for Lightning LoRA (NEW, can be bypassed)",
    "load_image": "Node ID 2 - LoadImage for init image",
    "positive_prompt": "Node ID 3 - CLIPTextEncode for positive prompt",
    "negative_prompt": "Node ID 4 - CLIPTextEncode for negative prompt",
    "vae_encode": "Node ID 5 - VAEEncode to convert image to latent",
    "sampler": "Node ID 6 - KSampler (seed, steps, cfg, denoise/strength)",
    "vae_decode": "Node ID 7 - VAEDecode",
    "save_image": "Node ID 8 - SaveImage"
  },
  "1": {
    "inputs": {
      "ckpt_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "10": {
    "inputs": {
      "model": [
        "1",
        0
      ],
      "lora_name": "Qwen-Image-Edit-Lightning-8steps-V1.0.safetensors",
      "strength_model": 1.0
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load Lightning LoRA (Optional)"
    },
    "_note": "This node can be bypassed by setting mode=4. The server.py will set mode=4 when quality='standard' or 'high'."
  },
  "2": {
    "inputs": {
      "image": "PLACEHOLDER_INIT_IMAGE_NAME",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3": {
    "inputs": {
      "text": "PLACEHOLDER_POSITIVE_PROMPT",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive)"
    }
  },
  "4": {
    "inputs": {
      "text": "",
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative)"
    }
  },
  "5": {
    "inputs": {
      "pixels": [
        "2",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "6": {
    "inputs": {
      "seed": 0,
      "steps": 30,
      "cfg": 5.0,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 0.7,
      "model": [
        "10",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    },
    "_note": "Model input comes from LoRA loader (node 10). When LoRA is bypassed, this will still work as the LoRA passthrough outputs the model."
  },
  "7": {
    "inputs": {
      "samples": [
        "6",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "filename_prefix": "qwen_edit",
      "images": [
        "7",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}
