{
  "_comment": "ComfyUI API workflow for Qwen txt2img generation",
  "_mapping_instructions": {
    "description": "This is a template workflow. Replace the inputs in the nodes below with actual values.",
    "node_mappings": {
      "1": {
        "class_type": "CLIPTextEncode",
        "description": "Positive prompt encoder",
        "inputs_to_patch": {
          "text": "Set from tool parameter: prompt"
        }
      },
      "2": {
        "class_type": "CLIPTextEncode",
        "description": "Negative prompt encoder",
        "inputs_to_patch": {
          "text": "Set from tool parameter: negative_prompt"
        }
      },
      "3": {
        "class_type": "EmptyLatentImage",
        "description": "Latent image size",
        "inputs_to_patch": {
          "width": "Set from tool parameter: width",
          "height": "Set from tool parameter: height",
          "batch_size": "Set from tool parameter: batch_size"
        }
      },
      "4": {
        "class_type": "KSampler",
        "description": "Main sampler node",
        "inputs_to_patch": {
          "seed": "Set from tool parameter: seed (or random)",
          "steps": "Set from tool parameter: steps",
          "cfg": "Set from tool parameter: guidance"
        }
      },
      "5": {
        "class_type": "CheckpointLoaderSimple",
        "description": "Load Qwen model checkpoint",
        "inputs_to_patch": {
          "ckpt_name": "qwen_model.safetensors or your actual checkpoint name"
        }
      },
      "6": {
        "class_type": "VAEDecode",
        "description": "Decode latents to image"
      },
      "7": {
        "class_type": "SaveImage",
        "description": "Save output image",
        "inputs_to_patch": {
          "filename_prefix": "qwen_txt2img"
        }
      }
    }
  },
  "1": {
    "inputs": {
      "text": "PLACEHOLDER_PROMPT",
      "clip": ["5", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "2": {
    "inputs": {
      "text": "PLACEHOLDER_NEGATIVE_PROMPT",
      "clip": ["5", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "3": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "4": {
    "inputs": {
      "seed": 0,
      "steps": 20,
      "cfg": 5.0,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1.0,
      "model": ["5", 0],
      "positive": ["1", 0],
      "negative": ["2", 0],
      "latent_image": ["3", 0]
    },
    "class_type": "KSampler"
  },
  "5": {
    "inputs": {
      "ckpt_name": "qwen_model.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "6": {
    "inputs": {
      "samples": ["4", 0],
      "vae": ["5", 2]
    },
    "class_type": "VAEDecode"
  },
  "7": {
    "inputs": {
      "filename_prefix": "qwen_txt2img",
      "images": ["6", 0]
    },
    "class_type": "SaveImage"
  }
}
